# -*- coding: utf-8 -*-
"""Proyek Akhir : Membuat Model Sistem Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12gIWbFrphlXp1nahddMipKg5eSma7b8F

# **Import Library**
"""

# Standar libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# TensorFlow dan Keras
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models

# Pemrosesan teks & similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# File handling (jika diperlukan untuk Google Colab)
from google.colab import files

"""# **Data Loading**

Langkah ini bertujuan untuk **memuat dataset** yang diperlukan untuk membangun sistem rekomendasi. Karena proyek ini dijalankan di Google Colab, digunakan fungsi `files.upload()` dari modul `google.colab` untuk **mengunggah file CSV** dari komputer lokal ke lingkungan Colab.
"""

# Upload file
uploaded = files.upload()

"""# **Data Understanding**

Pada tahap ini, kita mulai dengan **memuat dan memahami dataset** yang digunakan dalam sistem rekomendasi. Tujuan dari tahap ini adalah untuk mendapatkan wawasan awal terkait data yang akan digunakan, yang akan sangat berguna untuk proses **data preparation** dan **modeling** selanjutnya.
"""

# Load datasets
rating = pd.read_csv('/content/tourism_rating.csv')
place = pd.read_csv('/content/tourism_with_id.csv')

rating.head()

rating.info()

place.head()

place.info()

"""## **Exploratory Data Analysis**

Langkah ini membantu untuk **memahami kondisi data** secara umum, baik dari sisi jumlah data, distribusi rating, dan jenis tempat wisata yang ada.
"""

print('\nStatistik rating:')
print(rating.describe())

# Distribusi rating
sns.histplot(rating['Place_Ratings'], bins=5, kde=True)
plt.title('Distribusi Rating')
plt.xlabel('Rating')
plt.ylabel('Frekuensi')
plt.show()

print('\nStatistik pengguna dan tempat yang dirating:')
print('Jumlah userID unik: ', len(rating.User_Id.unique()))
print('Jumlah placeID unik: ', len(rating.Place_Id.unique()))
print('Jumlah total data rating: ', len(rating))

print('Banyak data tempat wisata: ', len(place.Place_Id.unique()))
print('Kategori tempat wisata yang tersedia: ', place.Category.unique())

# Kategori tempat wisata
print('Kategori unik:', place.Category.unique())
sns.countplot(y=place['Category'], order=place['Category'].value_counts().index)
plt.title('Distribusi Kategori Tempat Wisata')
plt.show()

"""# **Data Preparation**

Pada tahap ini, kita **memperbaiki dan membersihkan** data yang telah dimuat sebelumnya agar siap digunakan dalam model rekomendasi. Dengan langkah ini, dataset menjadi lebih rapi dan siap digunakan dalam tahap berikutnya, yaitu **modeling** untuk sistem rekomendasi.
"""

# Mengecek missing value pada data rating
rating.isnull().sum()

# Mengecek missing value pada data place
place.isnull().sum()

# Drop kolom yang memiliki missing value
place = place.dropna(axis=1)
place.isnull().sum()

# Cek duplikat
print("Jumlah data duplikat pada rating: ", rating.duplicated().sum())
print("Jumlah data duplikat pada place: ", place.duplicated().sum())

# Menampilkan semua baris yang merupakan duplikat identik
duplikat_identik = rating[rating.duplicated(keep=False)]

# Menampilkan hasilnya
print(duplikat_identik)

# Hapus duplikat identik
rating = rating.drop_duplicates()

# Cek duplikat
print("Jumlah data duplikat pada rating: ", rating.duplicated().sum())

# Mengonversi series menjadi list
place_id = place['Place_Id'].tolist()
place_name = place['Place_Name'].tolist()
place_category = place['Category'].tolist()

print('\nJumlah ID:', len(place_id))
print('Jumlah Nama:', len(place_name))
print('Jumlah Kategori:', len(place_category))

# Membuat DataFrame akhir untuk digunakan dalam sistem rekomendasi
tourism_df = pd.DataFrame({
    'id': place_id,
    'place_name': place_name,
    'category': place_category
})

# Menampilkan data akhir
tourism_df

"""# **Model Development dengan Content Based Filtering**

Pada tahap ini, kita mengembangkan model rekomendasi dengan pendekatan **Content-Based Filtering** yang mengandalkan kesamaan kategori tempat wisata. Langkah ini menghasilkan model rekomendasi yang dapat memberikan daftar tempat wisata serupa berdasarkan kategori, yang merupakan contoh penerapan **content-based filtering**.
"""

# Cek data
data = tourism_df
data.sample(5)

"""## **TF-IDF Vectorizer**

**TF-IDF (Term Frequency-Inverse Document Frequency)** digunakan untuk mengubah teks kategori tempat wisata menjadi representasi numerik yang bisa digunakan dalam perhitungan kesamaan.
"""

# Inisialisasi TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer()

# Melakukan fit pada data kategori wisata
tfidf_vectorizer.fit(data['category'])

# Menampilkan nama-nama fitur (kategori wisata)
tfidf_vectorizer.get_feature_names_out()

# Transformasi ke dalam bentuk matriks TF-IDF
tfidf_matrix = tfidf_vectorizer.fit_transform(data['category'])

# Ukuran matriks TF-IDF
tfidf_matrix.shape

# Cek representasi matriks dalam bentuk dense
tfidf_matrix.todense()

# Membuat DataFrame TF-IDF untuk interpretasi
pd.DataFrame(
tfidf_matrix.todense(),
columns=tfidf_vectorizer.get_feature_names_out(),
index=data.place_name
).sample(5, axis=1).sample(10, axis=0)

"""## **Cosine Similarity**

**Cosine similarity** dihitung menggunakan `cosine_similarity()` untuk mengukur kesamaan antar tempat wisata berdasarkan kategori mereka.
"""

# Menghitung cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat DataFrame cosine similarity
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['place_name'], columns=data['place_name'])

print('Shape:', cosine_sim_df.shape)

# Menampilkan sebagian similarity matrix
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""## **Evaluasi**

Fungsi ini digunakan untuk **mengevaluasi kualitas rekomendasi** tempat wisata berdasarkan **kesamaan kategori** menggunakan pendekatan **Content-Based Filtering**. Jika `Precision@5 = 0.60`, berarti sekitar **60% kategori** dari rekomendasi **relevan** atau **mirip** dengan tempat wisata yang dijadikan acuan.
"""

def evaluate_recommendation(place_name, top_k=5, similarity_data=cosine_sim_df, items=data[['place_name', 'category']]):
    """
    Evaluasi untuk rekomendasi berdasarkan kesamaan kategori dengan menggunakan cosine similarity
    Parameters:
    - place_name: nama tempat wisata yang dijadikan acuan
    - top_k: jumlah rekomendasi yang diinginkan
    - similarity_data: matriks similarity antar tempat wisata
    - items: DataFrame yang berisi place_name dan kategori

    Returns:
    - Precision@K yang dihitung berdasarkan overlap kategori
    """
    # Ambil rekomendasi tempat wisata berdasarkan nama tempat
    recommendations = tourism_recommendations(place_name, similarity_data, items, k=top_k)

    if recommendations.empty:
        print("Tidak ada rekomendasi ditemukan.")
        return

    # Ambil kategori dari tempat wisata input
    query_category = data[data['place_name'].str.lower() == place_name.lower()]['category'].values[0]
    query_categories = set(query_category.lower().replace(", ", ",").split(","))

    total_overlap = 0
    category_counts = []

    # Cek berapa banyak kategori yang cocok di setiap rekomendasi
    for _, row in recommendations.iterrows():
        rec_categories = set(row['category'].lower().replace(", ", ",").split(","))
        overlap = query_categories.intersection(rec_categories)
        total_overlap += len(overlap)
        category_counts.append(len(rec_categories))

    # Hitung Precision@K (rata-rata overlap kategori per rekomendasi)
    precision_at_k = total_overlap / sum(category_counts)

    print(f"Evaluasi untuk rekomendasi berdasarkan '{place_name}':")
    print(f"Kategori tempat wisata input: {query_categories}")
    print(f"Total overlap kategori: {total_overlap}")
    print(f"Precision@{top_k}: {precision_at_k:.2f}")

evaluate_recommendation("Gedung Sate")

"""## **Fungsi Rekomendasi Tempat Wisata**

Fungsi `tourism_recommendations()` digunakan untuk memberikan rekomendasi tempat wisata berdasarkan kesamaan kategori. Fungsi ini menerima nama tempat wisata sebagai input, mencari tempat-tempat wisata yang memiliki kesamaan kategori tinggi dengan tempat tersebut, dan mengembalikan **k** rekomendasi tempat wisata teratas.
"""

def tourism_recommendations(place_name, similarity_data=cosine_sim_df, items=data[['place_name', 'category']], k=5):
    """
    Memberikan rekomendasi tempat wisata berdasarkan kesamaan kategori
    Parameters:
    - place_name: nama tempat wisata yang dijadikan acuan
    - similarity_data: matriks similarity antar tempat wisata
    - items: DataFrame yang berisi place_name dan kategori
    - k: jumlah rekomendasi yang diinginkan

    Returns:
    - DataFrame berisi daftar tempat wisata yang mirip
    """
    index = similarity_data.loc[:, place_name].to_numpy().argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(place_name, errors='ignore')  # menghindari return tempat yang sama
    return pd.DataFrame(closest).merge(items).head(k)

data[data.place_name.eq('Gedung Sate')]

tourism_recommendations('Gedung Sate')

"""# **Model Development dengan Collaborative Filtering**

Pada tahap ini, kita mengembangkan model rekomendasi dengan pendekatan **Collaborative Filtering** menggunakan metode **Neural Network** untuk memprediksi rating yang belum diberikan oleh pengguna pada tempat wisata tertentu. Dengan langkah-langkah ini, kita membangun model **Collaborative Filtering** menggunakan neural network untuk memberikan rekomendasi yang lebih personal berdasarkan perilaku pengguna dalam memberikan rating pada tempat wisata.

## **Data Preparation**

Tahap ini mengubah ID pengguna dan tempat wisata menjadi representasi numerik (encoding) menggunakan dictionary yang memetakan ID asli ke ID yang lebih kecil (encoded) untuk digunakan dalam model neural network. Ini dilakukan dengan `user_to_user_encoded` dan `place_to_place_encoded` untuk memetakan ID asli ke ID numerik.
"""

# Mengubah User_Id menjadi list tanpa nilai yang sama
user_ids = rating['User_Id'].unique().tolist()
print('list User_Id: ', user_ids)

# Melakukan encoding User_Id
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded User_Id : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded User_Id : ', user_to_user_encoded)

# Mengubah Place_Id menjadi list tanpa nilai yang sama
place_ids = rating['Place_Id'].unique().tolist()
print('list Place_Id: ', place_ids)

# Melakukan encoding Place_Id
place_to_place_encoded = {x: i for i, x in enumerate(place_ids)}
print('encoded Place_Id : ', place_to_place_encoded)

place_encoded_to_place = {i: x for i, x in enumerate(place_ids)}
print('encoded Place_Id : ', place_to_place_encoded)

# Mapping User_Id ke dataframe user
rating['user'] = rating['User_Id'].map(user_to_user_encoded)

# Mapping Place_Id ke dataframe place
rating['place'] = rating['Place_Id'].map(place_to_place_encoded)

# Menampilkan sample data setelah mapping
display(rating.head())

"""## **Membagi Data untuk Training dan Validasi**

Langkah ini adalah **tahapan penting sebelum training model Collaborative Filtering berbasis Neural Network**, memastikan data dalam format yang tepat dan terbagi secara adil untuk pelatihan dan evaluasi.
"""

# Mengacak dataset
rating = rating.sample(frac=1, random_state=42)

# Membuat variabel x untuk mencocokkan data user dan tempat wisata
x = rating[['user', 'place']].values

# Mengubah rating menjadi nilai float (normalisasi)
min_rating = rating['Place_Ratings'].min()
max_rating = rating['Place_Ratings'].max()
y = rating['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * rating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""## **Proses Training**

Membangun arsitektur **Recommender System berbasis embeddings** untuk mempelajari hubungan antara pengguna dan tempat wisata dari data rating.
"""

# Membangun model Neural Network
class RecommenderNet(tf.keras.Model):

    def __init__(self, num_users, num_places, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_places = num_places
        self.embedding_size = embedding_size
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=tf.keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)
        self.place_embedding = layers.Embedding(
            num_places,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=tf.keras.regularizers.l2(1e-6)
        )
        self.place_bias = layers.Embedding(num_places, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        place_vector = self.place_embedding(inputs[:, 1])
        place_bias = self.place_bias(inputs[:, 1])

        dot_user_place = tf.tensordot(user_vector, place_vector, 2)

        x = dot_user_place + user_bias + place_bias

        return tf.nn.sigmoid(x)

# Inisialisasi model
num_users = len(user_to_user_encoded)
num_places = len(place_to_place_encoded)
model = RecommenderNet(num_users, num_places, 50)

# Compile model
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Training model
history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=8,
    epochs=100,
    validation_data=(x_val, y_val)
)

"""## **Evaluasi**

Untuk **mengevaluasi kinerja model** selama proses pelatihan (training) dan validasi dengan melihat **error** pada setiap epoch.
"""

# Visualisasi metrik untuk mengevaluasi performa model
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model Metrics')
plt.ylabel('Root Mean Squared Error')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

"""**Overfitting**

* Perbedaan antara kurva train dan validation menunjukkan bahwa model mulai overfit.
* Setelah itu, error pada validation set tidak membaik bahkan cenderung naik meski error pada training set tetap menurun.

## **Fungsi Rekomendasi Tempat Wisata**

Menampilkan **rekomendasi tempat wisata personalisasi** untuk satu user tertentu berdasarkan model **Collaborative Filtering**. Langkah ini menyimulasikan bagaimana sistem memberikan rekomendasi tempat wisata baru kepada user berdasarkan **riwayat kunjungan dan kesamaan preferensi** dari user lain menggunakan Collaborative Filtering.
"""

# Menampilkan rekomendasi tempat wisata untuk user tertentu
user_id = rating['User_Id'].sample(1).iloc[0]
print(f"User ID yang dipilih: {user_id}")

# Tempat yang sudah dikunjungi user
places_visited_by_user = rating[rating['User_Id'] == user_id]
place_ids_visited = places_visited_by_user['Place_Id'].values
print(f"User ini telah mengunjungi {len(place_ids_visited)} tempat.")

# Menentukan tempat wisata yang belum dikunjungi oleh user
places_not_visited = tourism_df[~tourism_df['id'].isin(place_ids_visited)]
places_not_visited_encoded = [
    place_to_place_encoded[x] for x in places_not_visited['id'].values
    if x in place_to_place_encoded
]

# Siapkan data input untuk prediksi
user_encoded = user_to_user_encoded[user_id]
user_place_array = np.hstack([
    np.array([[user_encoded]] * len(places_not_visited_encoded)),
    np.array(places_not_visited_encoded).reshape(-1, 1)
])

# Prediksi rating untuk tempat yang belum dikunjungi
predicted_ratings = model.predict(user_place_array).flatten()

# Ambil top-N rekomendasi
top_n = 10
top_indices = predicted_ratings.argsort()[-top_n:][::-1]
recommended_encoded_ids = [places_not_visited_encoded[i] for i in top_indices]
recommended_place_ids = [place_encoded_to_place[i] for i in recommended_encoded_ids]

print('\n' + '=' * 30)
print('Places with HIGH ratings by the user:')
print('-' * 30)

# Tempat dengan rating tinggi oleh user tersebut
top_rated_places = places_visited_by_user.sort_values(by='Place_Ratings', ascending=False).head(5)
top_place_ids = top_rated_places['Place_Id'].values
top_places_info = tourism_df[tourism_df['id'].isin(top_place_ids)]

for row in top_places_info.itertuples():
    print(f"{row.place_name} : {row.category}")

print('\n' + '-' * 30)
print(f'Top {top_n} place recommendations:')
print('-' * 30)

# Tampilkan rekomendasi
recommended_places_info = tourism_df[tourism_df['id'].isin(recommended_place_ids)]
for row in recommended_places_info.itertuples():
    print(f"{row.place_name} : {row.category}")